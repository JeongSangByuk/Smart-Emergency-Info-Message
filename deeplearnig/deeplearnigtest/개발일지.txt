사용 데이터
1. 텍스트 평균 유사도(A)
2. 텍스트 최대 유사도(B)
3. 특정 키워드에 따른 가중치(C)

재난문자 카테고리 = '(코로나)안전수칙', '(코로나)발생,방역', '(코로나)동선', '경제,금융', '재난,날씨'

한 개의 재난문자에 대해 각각의 카테고리의 A + B + C 값을 구한다.

case 1. A + B + C의 최대 값이 코로나 문자일 경우,

정확도를 위해 '경제금융', '재난날씨' 유사도를 0으로 처리.(경제금융 재난날씨 데이터 양너무 적어서ㅠ 불가피..)

	1.1 각각의 카테고리에 대해 max(A) 와 max(B) 가 가르키는 카테고리가 같을 경우
	!! A(100%) + B(30%) 의 값을 백분율화 해서 마지막 유사도 책정.
	
	1.2 각각의 카테고리에 대해 max(A) 와 max(B) 가 가르키는 카테고리가 다를 경우
	!! A(100%) + B(100%) 의 값을 백분율화 해서 마지막 유사도 책정.

case 2. A + B + C의 최대값이 경제금융, 재난날씨

정확도를 위해 '(코로나)안전수칙', '(코로나)발생,방역', '(코로나)동선' 유사도를 0으로 처리.
!! B(100%) 의 값을 백분율화해서 마지막 유사도 책정.


결국의 해답
skicit learn 이용해서 tf/idf 를 사용하여 문장 유사도 측정

내가 생각하는 keras, LSTM 모델 사용시 분류가 잘 안되는 이유.
훈련 데이터 자체가 매우 적으며, 불용어 제거하고 토크나이징 하면 문자 하나의
토큰 양들이 매우 적어진다. 토큰의 양이 적어지는데 카테고리 별로 겹치는 토큰들은 상당하고
비슷하기 때문에 판단하기 매우 어렵다.

때문에 TF/IDF 를 통한 문장 유사도 측정이 가장 적합한 방법으로 판단된다.
사실 내가 텐서플로우의 학습에 대한 정확한 이해가 잘안되서 간단한 방법인 TF/IDF 방법이
가장 정확도 높았는지도 모르겠다.. 결국 멀리 멀리 돌아 TF/IDF 알고리즘을 써야할 것 같다.

--

텍스트 분류의 정확도를 높이기 위해

1. 불용어 제거
재난문자에서 주소와 관련된 정보들은 재난 문자 카테고리 분류에서 중요하지 않은
정보라 판단되어 우리나라 시군구,읍면동과 같은 주소 텍스트를 제거.

Mecab 기반으로 NNG, NNP, VA, VV, VA+ETM, VV+EF 이 외의 문자 제거.

확진자 번호(~~지역 ~~번째 확진자), 방문일자(주로, xx:xx~xx:xx) 와 같은 부분 단어 하나로 만들어보기.

2. 임베딩 층에 Word2Vec 으로 Pre-trained 모델 주입

3. 데이터 정제
데이터셋의 카데고리 별 데이터 비율 맞추기.
학습데이터 확실한 데이터만 넣어보기.
train 데이터 수 늘리기

4. model 변화

5. 중요단어
발생방역 -> 발생, 방역, 소독, 완료, 역학, 확진자누적번호
동선 -> 선별진료, 받, 보건소, 검사, 연락바랍니다, 방문일자, 방문요일, 가까운, 연락, 유증상자
안전수칙 -> 거리두기,

정확도가 낮은 이후

1. 겹치는 단어 너무 많다
결국 텍스트 분류는 토크나이징 된 단어를 가지고 유사도 판별하는데 3개의 카테고리가 겹치는 단어
너무 많다.

2. 카테고리의 기준이 되는 단어 이외에 필요없는 단어들 많다.
-> 예를 들어 동선에서 구체적인 상호명

3. 문자의 내용이 적어서 오히려 더 판단이 힘든거 같아..

4. 데이터 너무 적다?

5. 모델 자체의 문제
LSTM 모델의 문제.

---------------------

케라스 텍스트 분류 공부

머신 러닝 학습 돌려 놓고 쓰는 개발 일지..
우리가 만드려는 앱은 재난 문자를 사용자가 설정한 옵션에 맞게
필요도,관심도를 평가해주는 어플이다. 그렇기 때문에 먼저 해야할게
재난문자 내용에 따른 분류가 필요했다. 
기존의 재난 문자 데이터를
기반으로 몇가지 카테고리를 나눠서 학습시키는 ai를 개발하는 것이
첫번째 과제.

분류 모델을 개발하기 위해 파이썬 텐서 플로우의 케라스를 활용하는 것으로
방향을 잡고 여러가지 정보를 찾아봤다.

1. 파이썬 
우선 처음 시작하기 힘들었던 점은 파이썬이라는 언어를 접해 본 적
없어서 환경도 처음부터 갖춰야했고, 문법이 익숙하지 않아서 꽤 헤맸던 것
같다.

2. 텐서플로우 2.xx
텐서플로우에 대한 정보를 알아보면서 느꼈던 점이, 텐서플로우 버전2와
1간의 차이가 꽤 크다는 것을 느꼈다. 물론 내가 아직 공부를 막 시작한 단계여서
그 차이가 커보이는 것 일 수 있으나, 웬만하면 2로 공부하고 싶어서 최신
자료들만 찾다보니 자료의 양이 적어져 공부하기 힘들었다.
솔직히 아직 어떤 차이가 있는지 막 체감은 안되지만.. 찾은 코드에
session, placeholder 과 같은 2에서는 없어진 코드들을 보면 읽기가 싫어지더라..

3. 텍스트 분류
카테고리 분류 하는 알고리즘은 텍스트 분류의 가장 기초였고
코드 자료들도 상당히 많았따.. 하지만 옛날부터 느껴왔던 점,
남의 코드는 이해하기 정말 힘들고, 코드에 대해 완벽하게 이해하지 않는
이상 남의 코드를 내가 함부로 만져서 발전시키기 어렵다.

또한 앞서 말했듯 텐서플로우1 버전으로 작성된 코드들을 거르고 찾다보니
정말 자료가없었다 ㅠㅠ 그래서 그냥 깃헙에서 누군가(생명의 은인) 
올려주신 제일 나의 상황에 맞는 코드를 잡고 쭉 따라쳐보면서 
나름의 연구?!를 했다. 메소드 하나하나 검색해가면서 텍스트 전처리하는 
과정을 공부했고 머신러닝 돌아가는 과정에 대해 이해하려고 했지만.. 
쉽지는 않았따.. 앞으로 하면서 많이 생각해봐야할 부분인 것 같다.

제일 고생했던 부분은 코드를 분명 똑같이 쳤는데도 나는 제대로 분류가
되지 않았던.. 이를 뭐같은 상황이었다. 분명 예시코드는 학습 정답률 75프로
정도 나오던데는 나는 16프로 나오더라 ㅋㅋ
돌고 돌아 그 이유는 model을 활용한 predict를 할때 model 뿐만아니라
Tokenizer로 분석한 token도 불러와야 했던 것.. 아오..
그렇지 않으면 모델을 사용할 때 예측을 하고픈 문장으로
토크나이징이 되기 때문에 학습의 결과가 아무 의미가 없는것이 된다.
애초에 원리가 잘이해안가서 이런 삽질이 발생한 것 같다..

token 과 model을 불러올줄 알게 된 것이 가장 큰 배움이었다..근 3일간..
정말 학습시키는 기초를 쌓았지 않나 싶다..!



